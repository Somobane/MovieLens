---
title: 'HarvardX Capstone: MovieLens'
author: "Somosree Banerjee"
date: "11/03/2020"
output:
  pdf_document: 
    fig_caption: yes
    keep_tex: yes
    latex_engine: lualatex
    toc: yes
  html_document: default
  always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## I. Introduction

This report is part of the capstone project of the EdX course "HarvardX: PH125.9x Data Science: Capstone". The goal is to challenge and demonstrate how the knowledge acquired through the different topics covered in "HarvardX: PH125.9x Data Science" can be applied in solving real world problems.

## II. Summary
For the MovieLens project, the data set provided is generated by the GroupLens research lab. The aim to create a recommendation system using the “prediction version of problem”. 
The report is split in three sections:
1. Data Loading and Data Wrangling for further Analysis
2. Data Exploration and Analysis to understand the structure of the data set. 
3. A machine learning algorithm to calculate RMSE. "Penalized Least Square Approach" has been considered to calculate the RMSE.

## III. Data Loading and Data Wrangling

## Libraries Loaded
library(tidyverse)
library(caret)
library(data.table)
library(splitstackshape)
library(DT)
library(lubridate)

The data set ‘movielens’ gets split into a training-test set called ‘edx’ and a set for validation purposes called ‘validation’.

```{r movielens}
################################
# Create edx set, validation set
################################
#Memory 
memory.limit()
memory.limit(size=56000)

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(splitstackshape)) install.packages("splitstackshape", repos = "http://cran.us.r-project.org")
if(!require(DT)) install.packages("DT", repos = "http://cran.us.r-project.org")
if(!require(lubridate)) install.packages("lubridate", repos = "http://cran.us.r-project.org")

library(tidyverse)
library(caret)
library(data.table)
library(splitstackshape)
library(DT)
library(lubridate)
# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))
movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)

colnames(movies) <- c("movieId", "title", "genres")
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],title = as.character(title),
genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding")
# if using R 3.5 or earlier, use `set.seed(1)` instead
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)

```

## III. Data Exploration & Analysis
```{r edx}
summary(edx)
```
#Quantitative:Rating Analysis

# Table Showing the Rating Count
```{r ratings}
head(sort(table(edx$rating)),10)
```
#Plot Histogram (Graphical Representation)
```{r ratings Graphical Representation}
ggplot(edx, aes(x= edx$rating)) +
  geom_histogram( binwidth = 0.2) +
  scale_x_continuous(breaks=seq(0, 5, by= 0.5)) +
    labs(x="Rating", y="No. of ratings", caption = "Source Data: edx set") +
  ggtitle("Histogram : Ratings Tally")
```
#Conclusions:
The above graphical representation concludes the following facts:
1. No user had given 0 as rating
2. The top 5 ratings from most to least are :  4, 3, 5, 3.5 and 3. The half star ratings are less common than whole star ratings.

#Quantitative:Movie Id Vs Ratings Analysis
#Plot Histogram (Graphical Representation)
```{r MovieId}
edx %>% group_by(movieId) %>% summarize(n = n()) %>%
  ggplot(aes(movieId)) + geom_histogram(bins = 10) +
  labs(x="MovieID", y="No. of ratings", caption = "Source Data: edx set") +
  ggtitle("Number of Movies Ratings")
```
#Conclusion:
The above graphical representation for MovieID depicts that movies with few ratings tend to have  more volatile ratings than movies which are rated more.
#Quantitative:UserId Vs Ratings Analysis
#Plot Histogram (Graphical Representation)
```{r UserID}
edx %>% group_by(userId) %>% summarize(n = n()) %>%
  ggplot(aes(userId)) + geom_histogram(bins = 10) +
  labs(x="UserID", y="No. of ratings", caption = "Source Data: edx set") +
  ggtitle("Number of User Ratings")
```
#Conclusion:
The above graphical representation for User ID depicts that users who rate just a few movies tend to have  more volatile ratings than users who rate lots of movies
#Qualitative:Genres vs Ratings Analysis
1. Segregate and extract the Genres from the combination of Genres
```{r genres}
edx_Splitted <- cSplit(edx, "genres", sep = "|" ,  direction = "long")
```
2. Calculate the Rating Count per Genre
```{r genres Rating Count}
edx_Genre_rating <- edx_Splitted %>% 
  group_by(genres) %>%
  summarize(RatingCount = n()) %>%
  arrange(desc(RatingCount))
#Tabular Representation
datatable(edx_Genre_rating, rownames = FALSE, filter="top", options = list(pageLength = 50, scrollX=T) ) %>%
  formatRound('RatingCount',digits=0, interval = 3, mark = ",")
```
#Graphical representation (Point Chart)
```{r genres Graphical Plot}
ggplot(edx_Genre_rating, aes(x= genres, y=RatingCount)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90,hjust = 1))+
  scale_y_continuous(trans = "log2")+
  ggtitle("Genre - Ratings Point Chart")
```
#Conclusion:
The above tabular and graphical representation concludes that three Genres with the highest Rating count are:
1. Drama
2. Comedy
3. Action
Movies with "no genre" have least movie ratings (7).

#Qualitative:Movie Titles vs Ratings Analysis
Calculate the Rating Count per Movie
```{r MovieTitle Tabular Representation}
edx_Movie_Ratings <- edx %>% 
  group_by(title, genres) %>%
  summarize(RatingCount = n()) %>%
  arrange(desc(RatingCount))
#Tabular Representation
datatable(edx_Movie_Ratings, rownames = FALSE, filter="top", options = list(pageLength = 10, scrollX=T) ) %>%
  formatRound('RatingCount',digits=0, interval = 3, mark = ",")
```
#Graphical representation (Bar Chart)
```{r MovieTitle Graphical Representation}
edx %>% group_by(title) %>% summarise(count = n()) %>% top_n(10,count) %>%
  arrange(desc(count)) %>%
  ggplot(aes(x=reorder(title, count), y=count)) + coord_flip(y=c(0, 40000)) +
  geom_bar(stat='identity', fill="purple") + 
  labs(x="", y="Number of ratings") +
  geom_text(aes(label= count), hjust=-0.1, size=3) +
  labs(title=" Top 10 Movies \n on number on ratings" , caption = "source data: edx set")

```
#Conclusion:
The above tabular and graphical representation of "Movie Title" confirms previous analysis. The movies which have the highest number of ratings are in the top genres categories : movies like Pulp fiction (1994), Forrest Ump(1994) or Jurrasic Park(1993) which are in the top 5 of movie’s ratings number , are part of the Drama, Comedy or Action genres.

#Movie Age vs Movie Ratings
Extract Premier year from Movie Title
```{r PremierYear}
#RegEx could have been used as well, but there are movie titles with number in it resulting in wrong determination of Movie Year
PremierYear <- as.numeric(substr(as.character(edx$title),nchar(as.character(edx$title))-4,nchar(as.character(edx$title))-1))
```
Modify the Data Frame with Premier Year and also validate the Premier Year
```{r Premier_Year, Rated_Year}
edx_Movie_Aging_Details <- edx %>% mutate(Rated_Year = year(as_datetime(timestamp)), Premier_Year = PremierYear) %>% select(-timestamp)
head(edx_Movie_Aging_Details)

edx_Movie_Aging_Details %>% filter(Premier_Year < 1900 || Premier_Year > 2018) %>% group_by(movieId, title, Premier_Year,Rated_Year) %>% summarize(n = n())
```
# Calculate Movie Age and Average Rating
```{r Movie_Age, Avg_Movie_Rating}
edx_Movie_Aging_Details_Avg <- edx_Movie_Aging_Details %>% 
  mutate(Movie_age = 2018 - Premier_Year) %>% group_by(Movie_age) %>% summarize(avg_rating_by_age = mean(rating))%>% arrange(desc(Movie_age))
head(edx_Movie_Aging_Details_Avg)

```
#Graphical Representation (Point Chart) : Age of movie vs average movie rating
```{r MovieAge}
edx_Movie_Aging_Details_Avg %>%
  ggplot(aes(Movie_age, avg_rating_by_age)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90,hjust = 1))+
  ggtitle("Movie Age vs Average Movie Rating")

```
#Graphical Representation (Point Chart) : Premier Year vs average movie rating
```{r Premier_Year}
edx_avg_ratings <- edx_Movie_Aging_Details %>% group_by(Premier_Year) %>% summarise(avg_rating_by_age = mean(rating))
edx_avg_ratings %>% ggplot(aes(Premier_Year, avg_rating_by_age)) +   geom_point() +
  theme(axis.text.x = element_text(angle = 90,hjust = 1))+
  ggtitle("Premier Year vs Average Movie Rating")

```
#Conclusion:
The above two graphical representations of ""Movie Age" and "Premier Year" against Average Movie Rating provide us with the following two facts:
1. Higher ratings the older a movies is up to 90 years old, then the ratings drop.In other words, Movies from earlier decades have more volatile ratings which has to be considered during accuracy calculation.
2. Recent movies get more ratings. Movies earlier than 1930 get few ratings, whereas newer movies, especially in the 90s get far more ratings.

## IV. Result
MovieLens data set is a large data set (size 10M), hence an efficient method was needed to predict movie ratings. The PENALIZED LEAST SQUARE approach is based on the mean movie rating. This average is adjusted for user-effects and movie-effects in order to volatile ratings with respect to users and movies. To adjust for these effects, a penalty - LAMBDA - is taken into account.

#Determine Lambda
```{r RMSE}
#RMSE Calculation
RMSE <- function(true_ratings, predicted_ratings){
  sqrt(mean((true_ratings - predicted_ratings)^2))
}
lambdas <- seq(0,5,.5)
rmses <- sapply(lambdas, function(l){
  mu <- mean(edx_Movie_Aging_Details$rating)
  
  b_i <- edx_Movie_Aging_Details %>%
    group_by(movieId) %>%
    summarize(b_i = sum(rating - mu)/(n() + l))
  
  b_u <- edx_Movie_Aging_Details %>%
    left_join(b_i, by='movieId') %>% 
    group_by(userId) %>%
    summarize(b_u = sum(rating - b_i - mu)/(n() +l))
  
  predicted_ratings <- edx_Movie_Aging_Details %>%
    left_join(b_i, by = "movieId") %>%
    left_join(b_u, by = "userId") %>%
    mutate(pred = mu + b_i +  b_u) %>% .$pred
  
  return(RMSE(predicted_ratings, edx_Movie_Aging_Details$rating))
})
#Graphical Representation of Lambda &rmses
qplot(lambdas, rmses)
lambda <- lambdas[which.min(rmses)]
paste('Optimal RMSE of',min(rmses),'is achieved with Lambda',lambda)
```
Also, as per the above QPlot, the optimal RMSE is achieved with Lambda = 0.5
#Predicting the Validation Set using the optimal Lambda = 0.5
```{r Prediction}
mu <- mean(validation$rating)
l <- lambda
b_i <- validation %>%
  group_by(movieId) %>%
  summarize(b_i = sum(rating - mu)/(n() + l))

b_u <- validation %>%
  left_join(b_i, by='movieId') %>% 
  group_by(userId) %>%
  summarize(b_u = sum(rating - b_i - mu)/(n() +l))

predicted_ratings <- validation %>%
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId") %>%
  mutate(pred = mu + b_i +  b_u) %>% .$pred

RMSE(predicted_ratings, validation$rating)
```

After exploring the movies through graphical representations and calculating RMSE, it can be concluded that the best predictor for ratings was movieId, userId. The age of the movie didn’t change the RMSE
The RMSE calculated and validated against the Validation set - 0.8258487

